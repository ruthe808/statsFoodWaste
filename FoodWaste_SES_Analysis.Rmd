---
title: "Food Waste SES Analysis"
author: "Ruth Enriquez"
date: "2022-12-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#loading in libraries
library(here)
library(tidyverse)
library(janitor)
library(readxl)
library(dplyr)
library(ggplot2)
```

```{r}
#loading food waste data on wholesale and retail 
foodRaw <- read_excel(here("data", "foodWaste", "Food_Wholesale_Retail.xlsx"), sheet = "Data") |> 
  clean_names() |> 
  mutate(excessfood_tonyear_lowest = as.numeric(excessfood_tonyear_lowest), excessfood_tonyear_highest = as.numeric(excessfood_tonyear_highest)) |> 
  filter(is.na(excessfood_tonyear_lowest) == FALSE, is.na(excessfood_tonyear_highest) == FALSE, county != "NULL")

#loading in CA county & income census data
Census <- read_excel(here("data", "census2020.xlsx"), sheet = "Data2") |> 
  clean_names()
```

```{r}
#cleaning up foodRaw data
food <- foodRaw |> 
  select("county", "state", "excessfood_tonyear_lowest", "excessfood_tonyear_highest") |> 
  filter(state == "CA") |> 
  group_by(county) |> 
  summarise(Mean_Food_Waste_Low = mean(excessfood_tonyear_lowest), Mean_Food_Waste_High = mean(excessfood_tonyear_highest))
```

```{r}
#joining the food and census tables together
foodCensus <- left_join(Census, food, by = "county") |> 
  select("county",
         "mean_household_income_dollars",
         "Mean_Food_Waste_Low",
         "Mean_Food_Waste_High")
```

```{r}
#checking my data distribution
#incomeHist <- hist(foodCensus$mean_household_income_dollars)

incomeHist <- ggplot(data = foodCensus)+
  geom_histogram(aes(x =mean_household_income_dollars), fill = "cyan4")+
  theme_classic()+
  labs(title = "Histogram of Mean Household Income in Dollars",
       x = "Mean Household Income ($)")
  
#lowHist <- hist(foodCensus$Mean_Food_Waste_Low)
lowHist <- ggplot(data = foodCensus)+
  geom_histogram(aes(x = Mean_Food_Waste_Low), fill = "cyan4")+
  theme_classic()+
  labs(title = "Histogram of Mean Food Waste Low Estimate",
       x = "Mean Food Waste (Tons)")

#highHist <- hist(foodCensus$Mean_Food_Waste_High)
highHist <- ggplot(data = foodCensus)+
  geom_histogram(aes(x = Mean_Food_Waste_High), fill = "cyan4")+
  theme_classic()+
  labs(title = "Histogram of Mean Food Waste High Estimate",
       x = "Mean Food Waste (Tons)")

incomeHist
lowHist
highHist


```



```{r}
#initially checking if there is a relationship between average household income and average food waste produced
lowWaste <- ggplot(data = foodCensus,
                            aes(x = mean_household_income_dollars,
                                y = Mean_Food_Waste_Low)) +
  geom_point(size = 3) +
  theme_classic()

highWaste <- ggplot(data = foodCensus,
                            aes(x = mean_household_income_dollars,
                                y = Mean_Food_Waste_High)) +
  geom_point(size = 3) +
  theme_classic()

lowWaste
highWaste
```

```{r}
#Creating a simple linear regression on both food waste estimates

#Creating a linear regression on LOW food waste estimate
regLow <-lm(Mean_Food_Waste_Low ~ mean_household_income_dollars, data =foodCensus)

#Creating a linear regression on HIGH food waste estimate
regHigh <-lm(Mean_Food_Waste_High ~ mean_household_income_dollars, data =foodCensus)

summary(regLow)
summary(regHigh)
```
$$ \text{food_waste_low}_i = \beta_0 + \beta_1 \text{mean_household_income}_i + \varepsilon_i $$
$$ \text{food_waste_high}_i = \beta_0 + \beta_1 \text{mean_household_income}_i + \varepsilon_i $$
```{r}
#Plotting linear regression for LOW food waste estimate
lowWastePlot <- ggplot(data = foodCensus,
                       aes(x = mean_household_income_dollars,
                           y = Mean_Food_Waste_Low)) +
  labs(x = "Mean Household Income ($)",
      y = "Food Waste Low Estimate (tons)") +
  geom_point(alpha = 0.5, size = 3) + 
  geom_smooth(method ='lm', 
              formula = y~x, 
              color ="lightcoral", 
              se = F, size = 1.5) +
  theme_classic()

#Plotting linear regression for HIGH food waste estimate
highWastePlot <- ggplot(data = foodCensus,
                        aes(x = mean_household_income_dollars,
                            y = Mean_Food_Waste_High)) +
  labs(x = "Mean Household Income ($)",
      y = "Food Waste Estimate - High (tons)") +
  geom_point(alpha = 0.5, size = 3) + 
  geom_smooth(method ='lm',
              formula = y~x,
              color ="lightcoral",
              se = F,
              size = 1.5) +
  theme_classic()

gridExtra::grid.arrange(lowWastePlot, highWastePlot)
```

```{r}
#loading in county by region data
region <- read_excel(here("data", "countyRegion.xlsx"))


#Making a region/county data frame with food waste data
#Use later for getting count to calculate pvalue
foodRegion<- left_join(foodCensus, region, by = "county")


regionIncome <- foodRegion |> 
  group_by(Region) |> 
  summarise(mean(mean_household_income_dollars))

```


Stating null and alternative hypotheses for low food waste estimate

$$H_{0}: \mu_{SoSJ} - \mu_{SfBay} = 0$$ $$H_{A}: \mu_{SoSJ} - \mu_{SfBay} \neq 0$$

```{r}
#Looking at regional trend for LOW estimate
foodRegionLow<- left_join(foodCensus, region, by = "county") |> 
  group_by(Region) |> 
  summarise(Mean_Low = mean(Mean_Food_Waste_Low),
            SD_Low = sd(Mean_Food_Waste_Low))

#Computing point estimate of your parameter of interest
#finding the mean inputs for the point estimate calculation
muSoSjL <- (foodRegionLow$Mean_Low[foodRegionLow$Region=="Southern San Joaquin Valley"])
muSfBayL <- (foodRegionLow$Mean_Low[foodRegionLow$Region=="San Francisco Bay Area"])

#calculating point estimate
#does the order matter, it doesn't just keep it consistent and know where in the graph you're looking at data.
pointEstL = round(as.numeric(muSoSjL - muSfBayL) , 3)
#print(paste0("The poinst estimate is ", pointEstL))

#calculating standard error
#getting the count of each state in a region
#0 is still meaninful, but missing is not
countSoSj = foodRegion |> 
  filter(Region == "Southern San Joaquin Valley") |> 
  count()
countSfBay = foodRegion |> 
  filter(Region == "San Francisco Bay Area") |> 
  count()

#calling out the standard deviation
sdSoSjL <- (foodRegionLow$SD_Low[foodRegionLow$Region=="Southern San Joaquin Valley"])
sdSfBayL <- (foodRegionLow$SD_Low[foodRegionLow$Region=="San Francisco Bay Area"])


#calculating standard error
seFoodL = round(as.numeric(sqrt(sdSoSjL^2/countSoSj + sdSfBayL^2/countSfBay)),3)
#print(seFrost)

#calculating test statistic/zscore
zScoreL = round(((pointEstL - 0)/seFoodL),3)
#print(zScoreL)
#print(paste0("The stardard error for frost is ", seFoodL, ". The test statistic or zscore is ", zScoreL))

#calculating our p-value using pt
#degrees of freedom = 26
#wanting to look at positive values, use lower.tail = FALSE
pvalL <- pt(zScoreL, 26, lower.tail = FALSE)
#print(paste0("The p-value is ", pvalL))
print(paste0("With the p-value being ", pvalL, " I would fail to reject the null hypothesis because of p-value is less than our alpha"))

```

```{r}
#Doing a t.test to check my work
t.test(foodRegion$Mean_Food_Waste_Low[foodRegion$Region=="Southern San Joaquin Valley"], foodRegion$Mean_Food_Waste_Low[foodRegion$Region=="San Francisco Bay Area"])
```

Stating null and alternative hypotheses for high food waste estimate

$$H_{0}: \mu_{SoSJ} - \mu_{SfBay} = 0$$ $$H_{A}: \mu_{SoSJ} - \mu_{SfBay} \neq 0$$

```{r}
#Creating a dataframe at regional level using HIGH food waste estimate
foodRegionHigh<- left_join(foodCensus, region, by = "county") |> 
  group_by(Region) |> 
  summarise(Mean_High = mean(Mean_Food_Waste_High),
            SD_High = sd(Mean_Food_Waste_High))

#Computing point estimate of your parameter of interest
#finding the mean inputs for the point estimate calculation
muSoSj <- (foodRegionHigh$Mean_High[foodRegionHigh$Region=="Southern San Joaquin Valley"])
muSfBay <- (foodRegionHigh$Mean_High[foodRegionHigh$Region=="San Francisco Bay Area"])


#calculating point estimate
#does the order matter? it doesn't just keep it consistent and know where in the graph you're looking at data.
pointEst = round(as.numeric(muSoSj - muSfBay) , 3)
#print(paste0("The poinst estimate is ", pointEst))


#calling out the standard deviation
sdSoSj <- (foodRegionHigh$SD_High[foodRegionHigh$Region=="Southern San Joaquin Valley"])
sdSfBay <- (foodRegionHigh$SD_High[foodRegionHigh$Region=="San Francisco Bay Area"])

#calculating standard error
seFood = round(as.numeric(sqrt(sdSoSj^2/countSoSj + sdSfBay^2/countSfBay)),3)
#print(seFrost)

#calculating test statistic/zscore
zScore = round(((pointEst - 0)/seFood),3)
#print(zScore)
#print(paste0("The stardard error for frost is ", seFrost, ". The test statistic or zscore is ", zScore))

#calculating our p-value using pt
#degrees of freedom = 26
#wanting to look at positive values, use lower.tail = FALSE
pval <- pt(zScore, 26, lower.tail = FALSE)
#print(paste0("The p-value is ", pval))

print(paste0("With the p-value being ", pval, " I would reject the null hypothesis because of p-value is less than our alpha"))
```

```{r}
#Doing a t.test to check my work
t.test(x = foodRegion$Mean_Food_Waste_High[foodRegion$Region=="Northern San Joaquin Valley"], y = foodRegion$Mean_Food_Waste_High[foodRegion$Region=="San Francisco Bay Area"])
```









